\documentclass[12pt]{article}
\usepackage{style/style_sol}

\begin{document}

\begin{titlepage}
	\centering
	\vspace*{\fill}
	\Huge \textit{\textbf{Solutions MP/MP$^*$\\ Espaces préhilbertiens}}
	\vspace*{\fill}
\end{titlepage}

\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item $\varphi$ est une forme bilinéaire symétrique. Soit $f\in E$, on a 
		\begin{equation}
			\varphi(f,f)=\int_{0}^{1}f^{2}+f'^{2}\geqslant 0.
		\end{equation}
		Si $\varphi(f,f)=0$, $f^{2}$ étant continue et positive, on a $f=0$. 

		\item Soit $(f,g)\in V\times W$. On a 
		\begin{align}
			\int_{0}^{1}fg +f'g'
			&=\int_{0}^{1}fg+\int_{0}^{1}f'g',\\
			&=\int_{0}^{1}fg+[fg']_{0}^{1}-\int_{0}^{1}fg'',\\
			&=\int_{0}^{1}fg-\int_{0}^{1}fg,\\
			&=0.
		\end{align}

		Donc $V$ et $W$ sont orthogonaux.

		Soit $h\in E$. Supposons qu'il existe $(f,g)\in V\times W$ tel que $h=f+g$. Il existe $(a,b)\in\R^{2}$ tel que pour tout $x\in[0,1]$, $g(x)=a\e^{x}+b\e^{-x}$ et $f(0)=f(1)=0$. Donc $h(0)=a+b$ et $h(1)=a\e+\frac{b}{\e}$. On trouve donc 
		\begin{equation}
			\begin{array}[]{rcl}
				a &=& \frac{\frac{h(0)}{\e}-h(1)}{\frac{1}{\e}-\e},\\
				b &=& \frac{eh(0)-h(1)}{\e-\frac{1}{\e}}.
			\end{array}
		\end{equation}

		Réciproquement, en définissant $a$ et $b$ comme précédemment, on pose $f=h-g$. On a bien $f\in V$ et $h=f+g$. Finalement, $E= V\overset{\perp}{\oplus} W$.

		\item Si $h_0\in W\cap E_{\alpha,\beta}$, il existe $(a,b)\in\R^{2}$ tel que pour tout $x\in[0,1]$, $h_0(x)=a\cosh(x)+b\sinh(x)$, $h_0()=0=a=\alpha$ et $h_0(1)=a\cosh(1)+b\sinh(1)=\beta$ d'où 
		\begin{equation}
			b=\frac{\beta-\alpha\cosh(1)}{\sinh(1)}.
		\end{equation}

		Réciproquement, $h_0$ ainsi défini est dans $W\cap E_{\alpha,\beta}$.

		Pour tout $h\in E_{\alpha,\beta}$, $h-h_{0}\in V$, d'après le théorème de Pythagore, on a $\left\lVert h_0\right\rVert\leqslant\left\lVert h\right\rVert$. Ainsi, la borne supérieure est $\left\lVert h_0\right\rVert^{2}$.
	\end{enumerate}
\end{proof}

\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item Si $P\in\ker(\Delta)$, on a $P(X+a)=P(X)$ et par itération, pour tout $k\in\N$, $P(ka)=P(0)$, donc $P$ est constant. Ainsi, $\ker(\Delta)=\R_{0}[X]$. On a 
		\begin{equation}
			\Delta(X^{k})=(X+a)^{k}-X^{k}=\sum_{i=0}^{k-1}\binom{k}{i}X^{i}a^{k-i},
		\end{equation}
		de degré $k-1$ et de coefficient dominant $ka$. Ainsi, si $P=\sum_{i=0}^{n}X^{i}$ avec $a_n\neq0$, on a $\Delta(P)=\sum_{k=0}^{n}a_k\Delta(X^{k})$ de degré $n-1$ et de coefficient dominant $a_n na$.

		\item Si $k\geqslant\deg(P)+1$, on a $\Delta^{k}P=0$, et $\Delta^{\deg(P)}(P)=a_n\times n!a^{n}\neq0$. $\varphi$ est une somme finie, une forme bilinéaire symétrique, $\varphi(P,P)\geqslant0$ et si $P\neq0$, $\left(\Delta^{\deg(P)}P(0)\right)^{2}>0$ donc $\varphi(P,P)>0$.
		
		\item Soit $n\in\N$, cherchons $P_n$ de coefficient dominant strictement positif avec $\deg(P_n)=n$ tel que pour tout $k\in\left\llbracket0,\right\rrbracket$, $\Delta^{k}P_n(0)=\delta_{n,k}$. On a $P(0)=0$ pour $k=0$, et $\Delta(P)(0)=P(a)-P(0)=0$ donc $P(a)=0$. De proche en proche, pour tout $k\in\left\llbracket0,n-1\right\rrbracket$, $P(ka)=0$. Donc $P_n=\alpha_{n}X(X-a)\dots(X-(n-1)a)$, et $\Delta^{n}(P_n)(0)=1$ d'où 
		\begin{equation}
			\alpha_n = \frac{1}{n!a^{n}}.
		\end{equation}

		Réciproquement, en définissant $P_n$ comme ci-dessus, avec $P_0=1$, on a 
		\begin{align}
			\Delta(P_n)
			&=\alpha_n\left[(X+a)(X-a)\dots(X-(n-2)a)-X(X-a)\dots(X-(n-1)a)\right],\\
			&=\alpha_n X(X-a)\dots(X-(n-2)a)(na),\\
			&=P_{n-1}.
		\end{align}
		Par récurrence, $\Delta^{k}(P_n)(0)=\delta_{n,k}$ donc $(P_n)$ est orthonormée.
	\end{enumerate}
\end{proof}

\begin{proof}
	On choisit $E=\mathcal{C}^{0}\left(\left[0,\frac{\pi}{2}\right],\R\right)$ muni du produit scalaire $\int_{0}^{\frac{\pi}{2}}f(t)g(t)\d t=(f|g)$. Soit $f_0\colon x\mapsto 1$ et $f_1\colon x\mapsto x\in E$, on note $F=\Vect(f_0,f_1)$. Trouver $I(a,b)$ revient à calculer $p_F(\sin)=a_0 f_0+b_0 f_1$ avec $\sin-p_{F}(\sin)\in F^{\perp}$.

	On a 
	\begin{equation}
		(\sin -a_{0}f_1-b_{0}f_0|f_{0})=(\sin -a_{0}f_1-b_{0}f_0|f_{1})=0.
	\end{equation}
	D'où 
	\begin{equation}
		\begin{array}[]{rcl}
			\int_{0}^{\frac{\pi}{2}}\left(\sin(x)-a_0 x-b_{0}\right)\d x&=&0,\\
			\int_{0}^{\frac{\pi}{2}}\left(x\sin(x)-a_0 x^{2}-b_{0}x\right)\d x&=&0.
		\end{array}
	\end{equation}
	On trouve ainsi les valeurs de $b_0=\frac{8}{\pi^{2}}(\pi-3)$ et de $a_0=\frac{96}{\pi^{3}}\left(1-\frac{\pi}{4}\right)$ en résolvant un système de deux équations à deux inconnues en calculant les intégrales (utiliser une intégration par partie pour le calcul de celle d'intégrande $x\sin(x)$). Enfin,
	\begin{align}
		I(a,b)
		&=\left\lVert\sin-p_F(\sin)\right\rVert^{2},\\
		&=\left\lVert \sin\right\rVert^{2}-\left\lVert p_F(\sin)\right\rVert^{2}.
	\end{align}
	On finit par trouver $I(a,b)=1$.
\end{proof}

\begin{remark}
	Ce genre nde problème se résout souvent en se ramenant à un espace euclidien et en utilisant nos connaissances sur le projeté orthogonal.
\end{remark}

\begin{proof}
	\phantom{}
	\begin{enumerate}
		\item Si $k\geqslant\min(\deg(P),\deg(Q))$, $P^{(k)}(a_k)Q^{(k)}(a_k)=0$, donc $(\cdot|\cdot)$ est définie et est une forme bilinéaire symétrique positive.
		Soit $P\in E\setminus\left\lbrace0\right\rbrace$ avec $\deg(P)=k_{0}$. Si $(P|P)=0$, alors $\sum_{k=0}^{+\infty}\left(P^{(k)}(a_k)\right)^{2}=0$. En particulier, $P^{(k_0)}(a_{k_0})=0$ ce qui est absurde par définition de $k_0$. Donc $(\cdot|\cdot)$ est un produit scalaire.

		\item On applique le procédé d'orthogonalisation de Schmidt à $(X^{n})_{n\in\N}$.
		\item Soit $Q_n=\alpha_{0,n}+\alpha_{1,n}X+\dots+\alpha_{n,n}X^{n}$ de degré $n$. On a 
		\begin{equation}
			0=Q_n(a_0)=Q_n'(a_1)=\dots=Q_n^{(n-1)}(a_{n-1}),
		\end{equation}
		et $Q_n^{(n)}(a_n)=1$ si et seulement si 
		\begin{equation}
			\begin{array}[]{rcl}
				\alpha_{0,n}+\alpha_{1,n}a_{0}+\dots + \alpha_{n,n}a_{0}^{,}&=&0,\\
				\alpha_{1,n}+2\alpha_{2,n}a_{1}+\dots+n\alpha_{n,n}a_{1}^{n-1}&=&0,\\
				\vdots&\vdots&\vdots,\\
				(n-1)!\alpha_{n-1,n}+(n\times\dots\times2)\alpha_{n,n}a_{n-1}&=&0,\\
				n!\alpha_{n,n}&=&1.
			\end{array}
		\end{equation}
		Il y a une unique solution car c'est un système triangulaire. Ainsi, pour tout $k\in\left\lbrace0,\dots,n\right\rbrace$, $Q_n^{(k)}(a_k)=\delta_{n,k}$ et pour $k>n+1$, c'est vrai aussi car $Q_n^{(k)}=0$.

		On obtient ainsi une famille de polynômes telle que pour tout $n\in\N$, $\deg(Q_n)=0$ et le coefficient dominant de $Q_n$ est strictement positif. De plus pour tout $(n,m)\in\N^{2}$,
		\begin{equation}
			(Q_n|Q_m)=\sum_{k=0}^{+\infty}\underbrace{Q_n^{(k)}(a_k)Q_m^{(k)}(a_k)}_{\delta_{n,k}\delta_{m,k}}=\delta_{n,m}.
		\end{equation}

		Par unicité, $Q_n=P_n$ et $P_n^{(k)}(a_k)=\delta_{n,k}$.

		\item Comme $\int_{a_{n-1}}^{t_{n-1}}d t_{n}$ est un polynôme en $t_{n-1}$ de degré 1, si 
		\begin{equation}
			A_n(x)=\int_{a_{0}}^{x}\int_{a_1}^{t_1}\dots\int_{a_{n-1}}^{t_{n-1}}\d t_{n}\d t_{n-1}\dots\d t_{2}\d t_{1},
		\end{equation}
		alors c'est un polynôme en $x$ de degré $n$ et de coefficient dominant $\frac{1}{n!}$. De plus, pour tout $k\in\left\lbrace0,\dots,n\right\rbrace$,
		\begin{equation}
			A_n^{(k)}(t_k)=\int_{a_k}^{t_k}\dots\int_{a_{n-1}}^{t_{n-1}}\d t_{n}\dots\d t_{k+1}.
		\end{equation}
		Donc si $k\leqslant n-1$, $A_n^{(k)}(a_k)=0$, et si $k>n$, $A_{n}^{(k)}=0=A_n^{(k)}(a_k)$. Enfin, $A_n^{(n)}=1$. Donc $A_n=P_n$ par unicité.

		\item On a $P_0=1$, $P_1(x)=x$. On trouve $P_2(x)=\frac{1}{2}x(x-2\alpha)$ et $P_3(x)=\frac{x}{6}\left(x^{2}-6\alpha x+9\alpha^{2}\right)$. On vérifie alors par récurrence que $P_n=\frac{x}{n!}\left(x-n\alpha\right)^{n-1}$.
	\end{enumerate}
\end{proof}

\begin{proof}
	On note $\varphi(a,b,c)$ l'intégrale. On pose 
	\begin{equation}
		E=\left\lbrace f\in\mathcal{C}^{0}(\R_{+},\R)\middle| f^{2}(x)\e^{-x}\in\mathcal{L}^{1}(\R)\right\rbrace.
	\end{equation}
	$0\in E$, si $f\in E$, alors $\lambda f\in E$ pour tout $\lambda\in\R$ et si $(f,g)\in E^{2}$, alors $\left\lvert fg\right\rvert\leqslant\frac{1}{2}(f^{2}+g^{2})$ donc $g(x)g(x)\e^{-x}\in\mathcal{L}^{1}(\R_+)$, et $(f+g)^{2}=f^{2}+g^{2}+2fg$ donc $f+g\in E$.

	On définit pour tout $(f,g)\in E^{2}$,
	\begin{equation}
		(f|g)=\int_{0}^{+\infty}f(x)g(x)\e^{-x}\d x,
	\end{equation}
	qui est un produit scalaire sur $E$.

	Soit $f_k\colon x\mapsto x^{k}$ de $\R_{+}\to\R$, $F=\Vect(f_0,f_1,f_2)$. On a $\varphi(a,b,c)=\left\lVert\sin-af_2-bf_1-cf_0\right\rVert^{2}$ minimum pour $af_2-bf_1-cf_0=p_F(\sin)$.

	Par définition, $(a,b,c)$ vérifient $(\sin-af_2-bf_1-cf_0|f_k)=0$ pour tout $k\in\left\lbrace0,1,2\right\rbrace$.

	On a 
	\begin{equation}
		(\sin|f_0)=\int_{0}^{+\infty}\sin(x)\e^{-x}\d x=\Im\left(\int_{0}^{+\infty}\e^{-x(1-\i)}\d x\right)=\Im\left(\frac{1}{1-\i}\right)=\frac{1}{2},
	\end{equation}
	\begin{align}
		(\sin|f_1)
		&=\int_{0}^{+\infty}x\sin(x)\e^{-x}\d x,\\
		&=\Im\left(\int_{0}^{+\infty}x\e^{-x(1-\i)}\d x\right),\\
		&=\Im\left(\left[\frac{x\e^{-x(1-\i)}}{-(1-\i)}\right]_{0}^{+\infty}+\frac{1}{1-\i}\int_{0}^{+\infty}\e^{-x(1-\i)}\d x\right),\\
		&=\Im\left(0+\frac{1}{(1-\i)^{2}}\right),\\
		&=\frac{1}{2},
	\end{align}
	\begin{align}
		(\sin|f_2)
		&=\int_{0}^{+\infty}x^{2}\sin(x)\e^{-x}\d x,\\
		&=\Im\left(\int_{0}^{+\infty}x^{2}\e^{-x(1-\i)}\d x\right),\\
		&=\Im\left(0+\frac{2}{(1-\i)^{3}}\right),\\
		&=-\frac{1}{2}.
	\end{align}
	Soit $(i,j)\in\left\llbracket0,2\right\rrbracket^{2}$, on a 
	\begin{align}
		(f_i|f_j)
		&=\int_{0}^{+\infty}x^{i+j}\e^{-x}\d x,\\
		&=\Gamma(i+j+1),\\
		&=(i+j)!.
	\end{align}
	On résout ensuite le système 
	\begin{equation}
		\left\lbrace
			\begin{array}[]{rcl}
				a+b+2c &=&\frac{1}{2},\\
				a+2b+6c &=& \frac{1}{2},\\
				2a+6b+24c &=& -\frac{1}{2},
			\end{array}
		\right.
	\end{equation}
	et on finit par calculer $\left\lVert\sin-p_F(\sin)\right\rVert^{2}=\left\lVert\sin\right\rVert^{2}-\left\lVert p_F(\sin)\right\rVert^{2}$.
\end{proof}

\end{document}